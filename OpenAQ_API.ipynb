{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f1ac56-7b49-4930-a781-4fd9c74fc1d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import math\n",
    "from datetime import date\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "### Querying data from https://docs.openaq.org/docs/getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42f0bd09-9a77-47e3-9373-18756221094a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sensor_locations_in_canada( country_code = \"CA\", parameter = \"pm25\", limit = 1000):\n",
    "  # ISO 3166-1 alpha-2 country code for Montenegro\n",
    "\n",
    "    if(limit != 1000):\n",
    "        print(\"Warning, it's possible that this function only works with max limit 1000, and behaves weirdly otherwise\")\n",
    "        \n",
    "    url = f\"https://api.openaq.org/v2/locations?country={country_code}&parameter={parameter}&limit=1000\"#&offset=1000\"\n",
    "    #url = f\"https://api.openaq.org/v2/locations?country={country_code}&parameters_id=2&limit=1000\"#&offset=1000\"\n",
    "\n",
    "    headers = {\"accept\": \"application/json\", \"X-API-Key\": \"659706290b9f942d7b7e22e0e1667afc43164846ee91949f19f5a1312d2543e4\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if(response.status_code != 200):\n",
    "        print(response.text)\n",
    "\n",
    "    resj = response.json()\n",
    "    \n",
    "    foo = pd.DataFrame(resj['results'])\n",
    "    tot_pages = resj['meta']['found']\n",
    "    print(tot_pages)\n",
    "    div = tot_pages/limit\n",
    "    pages = math.ceil(div)\n",
    "    \n",
    "    #list_of_locations = pd.DataFrame(test['results'])\n",
    "    #tmp_frame = pd.DataFrame(test['results'])\n",
    "    \n",
    "    #list_of_locations = []\n",
    "    \n",
    "    df_raw = pd.DataFrame()\n",
    "    \n",
    "    for i in range(1, (pages+2)):\n",
    "        print(i)\n",
    "        url = f\"https://api.openaq.org/v2/locations?country={country_code}&parameter={parameter}&limit={limit}&page={i}\"\n",
    "        response2 = requests.get(url, headers=headers)\n",
    "        test = response2.json()\n",
    "        tmp_frame = pd.DataFrame(test['results'])\n",
    "        #print(tmp_frame)\n",
    "        df_raw = pd.concat([ df_raw,  tmp_frame], ignore_index = True, sort = False)\n",
    "        \n",
    "#     num_pages = 1\n",
    "#     while(len(tmp_frame) > 0): #(test['meta']['found'] + (limit*2)) > (test['meta']['limit'] * num_pages)\n",
    "        \n",
    "#         #print(test['meta']['found'],  (test['meta']['limit'] * num_pages))\n",
    "#         print(num_pages)\n",
    "#         url = f\"https://api.openaq.org/v2/locations?country={country_code}&parameter={parameter}&limit={limit}&page={num_pages}\"\n",
    "#         response = requests.get(url, headers=headers)\n",
    "#         test = response.json()\n",
    "#         tmp_frame = pd.DataFrame(test['results'])      \n",
    "#         list_of_locations = pd.concat([list_of_locations,  tmp_frame])\n",
    "#         num_pages =  num_pages + 1\n",
    "        \n",
    "        \n",
    "    return(df_raw)\n",
    "\n",
    "def unpack(df, column, fillna=None):\n",
    "    ret = None\n",
    "    if fillna is None:\n",
    "        ret = pd.concat([df, pd.DataFrame((d for idx, d in df[column].items()))], axis=1)\n",
    "        del ret[column]\n",
    "    else:\n",
    "        ret = pd.concat([df, pd.DataFrame((d for idx, d in df[column].items())).fillna(fillna)], axis=1)\n",
    "        del ret[column]\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d744ba3e-d36f-4117-986b-40be227d3f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_measument_per_location(locations_id, limit = 1000):\n",
    "    time.sleep(3)\n",
    "    if(limit != 1000):\n",
    "        print(\"Warning, it's possible that this function only works with max limit 1000, and behaves weirdly otherwise\")\n",
    "        \n",
    "    url = f\"https://api.openaq.org/v2/averages?parameters_id=2&date_to=2023-09-30T00%3A00%3A00&date_from=2023-05-01T00%3A00%3A00&country=CA&locations_id={locations_id}&limit=1&page=1\"\n",
    "\n",
    "    headers = {\"accept\": \"application/json\", \"X-API-Key\": \"659706290b9f942d7b7e22e0e1667afc43164846ee91949f19f5a1312d2543e4\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if(response.status_code != 200):\n",
    "        print(response.text)\n",
    "        if(response.status_code == 429):\n",
    "            return(None)\n",
    "            #time.sleep(300)\n",
    "        \n",
    "\n",
    "    test = response.json()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #list_of_locations = pd.DataFrame(test['results'])\n",
    "    #tmp_frame = pd.DataFrame(test['results'])\n",
    "    \n",
    "    #list_of_locations = []\n",
    "    \n",
    "    df_raw = pd.DataFrame()\n",
    "    if(test['meta']['found'] == 0):\n",
    "        print(test)\n",
    "        print(\"no entries found for id\", locations_id)\n",
    "        raise CustomException(\" \")\n",
    "    page = 1\n",
    "    while ((test['meta']['found'] != 0)):\n",
    "        time.sleep(1)\n",
    "        #print(page)\n",
    "        url = f\"https://api.openaq.org/v2/averages?parameters_id=2&date_to=2023-09-30T00%3A00%3A00&date_from=2023-05-01T00%3A00%3A00&country=CA&locations_id={locations_id}&limit=1000&page={page}\"\n",
    "        response2 = requests.get(url, headers=headers)\n",
    "        if(response2.status_code != 200):\n",
    "            print(response2.text)\n",
    "            if(response2.status_code == 429):\n",
    "                return(None)\n",
    "               # time.sleep(300)\n",
    "        test = response2.json()\n",
    "        \n",
    "        #print(test['meta']['found'])\n",
    "        tmp_frame = pd.DataFrame(test['results'])\n",
    "        #print(tmp_frame)\n",
    "        df_raw = pd.concat([ df_raw,  tmp_frame], ignore_index = True, sort = False)\n",
    "        page = page + 1\n",
    "        \n",
    "        \n",
    "    return(df_raw)\n",
    "\n",
    "def get_measument_per_location_special(locations_id, limit = 1000):\n",
    "    '''\n",
    "    Get measurment per location. Different than previous function because it will query over a larger timeframe, and then subset the result. \n",
    "    '''\n",
    "    #time.sleep(1)\n",
    "    if(limit != 1000):\n",
    "        print(\"Warning, it's possible that this function only works with max limit 1000, and behaves weirdly otherwise\")\n",
    "        \n",
    "    url = f\"https://api.openaq.org/v2/averages?parameters_id=2&date_to=2024-02-07T00%3A00%3A00&date_from=2023-05-01T00%3A00%3A00&country=CA&locations_id={locations_id}&limit=1&page=1\"\n",
    "\n",
    "    headers = {\"accept\": \"application/json\", \"X-API-Key\": \"659706290b9f942d7b7e22e0e1667afc43164846ee91949f19f5a1312d2543e4\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if(response.status_code != 200):\n",
    "        print(response.text)\n",
    "        if(response.status_code == 429):\n",
    "            return(None)\n",
    "            #time.sleep(300)\n",
    "        \n",
    "\n",
    "    test = response.json()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #list_of_locations = pd.DataFrame(test['results'])\n",
    "    #tmp_frame = pd.DataFrame(test['results'])\n",
    "    \n",
    "    #list_of_locations = []\n",
    "    \n",
    "    df_raw = pd.DataFrame()\n",
    "    if(test['meta']['found'] == 0):\n",
    "        print(test)\n",
    "        print(\"no entries found for id\", locations_id)\n",
    "        raise CustomException(\" \")\n",
    "    page = 1\n",
    "    while ((test['meta']['found'] != 0)):\n",
    "        #time.sleep(1)\n",
    "        #print(page)\n",
    "        url = f\"https://api.openaq.org/v2/averages?parameters_id=2&date_to=2024-02-07T00%3A00%3A00&date_from=2023-05-01T00%3A00%3A00&country=CA&locations_id={locations_id}&limit=1000&page={page}\"\n",
    "        response2 = requests.get(url, headers=headers)\n",
    "        if(response2.status_code != 200):\n",
    "            print(response2.text)\n",
    "            if(response2.status_code == 429):\n",
    "                return(None)\n",
    "               # time.sleep(300)\n",
    "        test = response2.json()\n",
    "        \n",
    "        #print(test['meta']['found'])\n",
    "        tmp_frame = pd.DataFrame(test['results'])\n",
    "        #print(tmp_frame)\n",
    "        df_raw = pd.concat([ df_raw,  tmp_frame], ignore_index = True, sort = False)\n",
    "        page = page + 1\n",
    "        \n",
    "    df_raw[(df_raw.hour <= \"2023-09-30 23:59:59\") & (df_raw.hour >= \"2023-05-01 00:00:00\")]\n",
    "    return(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e22d1a8b-6575-40df-97ae-70c6dc44cfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "2265\n"
     ]
    }
   ],
   "source": [
    "locs = get_sensor_locations_in_canada()\n",
    "\n",
    "locs.to_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/\" + \"Locations\" + str(date.today().strftime(\"%Y%m%d\")) +\".csv\")\n",
    "print(len(locs.id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2b53d3e-1405-4bbb-9b01-d51f40b0c3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Find number of IDS in the time range. (Not actually sure how strict the querying is, it might not drop IDS based on if they only partially overlap. Need to check). \n",
    "\n",
    "#2023-09-30T00%3A00%3A00&date_from=2023-05-01T00%3A00%3A00\n",
    "\n",
    "#start_time = datetime.datetime.strptime(\"2023-05-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "#end_time = datetime.datetime.strptime(\"2023-09-30 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "start_time = \"2023-05-01 00:00:00+00:00\"\n",
    "end_time = \"2023-09-30 00:00:00+00:00\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "len(locs[(locs.firstUpdated.astype('datetime64[ns, UTC]') <= start_time) & (locs.lastUpdated.astype('datetime64[ns, UTC]') >= end_time)].id.unique())\n",
    "\n",
    "locs_time = locs[(locs.firstUpdated.astype('datetime64[ns, UTC]') <= start_time) & (locs.lastUpdated.astype('datetime64[ns, UTC]') >= end_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "177924fd-cd47-4d6e-a540-097704bc341a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = locs.id.unique()\n",
    "\n",
    "all_measurments = pd.DataFrame()\n",
    "no_entries_id = list()\n",
    "\n",
    "\n",
    "for n,i in enumerate(ids, start = 0):\n",
    "    if(n == 0):\n",
    "        print(\"n = 0\")\n",
    "    elif((n%150) == 0):\n",
    "        time.sleep(3)\n",
    "    try:\n",
    "        foo = get_measument_per_location(i)\n",
    "    except CustomException as e:\n",
    "        no_entries_id.append(i)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error at ID: \",i)\n",
    "        print(e)\n",
    "        continue\n",
    "    ## Extract the period between \n",
    "    all_measurments = pd.concat([all_measurments, foo])\n",
    "    #print(fires)\n",
    "        #fr_pd = pd.DataFrame(fires, columns=[\"lat\", \"lon\", \"farea\", \"data_source\"])\n",
    "    all_measurments.to_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/\" + str(date.today().strftime(\"%Y%m%d\"))+  \".csv\")\n",
    "    tmp_df = pd.DataFrame(no_entries_id, columns= [\"none_found\"])\n",
    "    tmp_df.to_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/\" + \"missing_ids\"+ str(date.today().strftime(\"%Y%m%d\"))+  \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb66f5a0-e311-4f2d-b3ea-a286d9e3def6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Read in missing IDS from previous runs. These need to be handled differently becuase of the bug in the API\n",
    "\n",
    "missing_ids = pd.read_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/missing_ids20240201.csv\")\n",
    "\n",
    "missing_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "387d4ba8-4399-4987-8d1b-b70f76e1d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check file to see if it processed all the IDS. If not, subset to missing IDs and try again. \n",
    "\n",
    "sensors = pd.read_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/20240125.csv\")\n",
    "sensors2 = pd.read_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/20240126.csv\")\n",
    "sensor3 = pd.read_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/20240129.csv\")\n",
    "sensor4 = pd.read_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/20240130.csv\")\n",
    "sensor5 = pd.read_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/20240201.csv\")\n",
    "sensor6 = pd.read_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/20240207.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dd20a302-d67d-4c5a-9c48-dabb4c27ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check just on the IDS where there is temporal overlap \n",
    "\n",
    "sub_missing_ids = locs_time.id[~locs_time.id.isin([*sensors.id.unique(), *sensors2.id.unique(), *sensor3.id.unique(),  *sensor5.id.unique(), *sensor6.id.unique()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a391485-96cf-4b64-9789-96d8487fbf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: id, dtype: int64)\n",
      "Series([], Name: none_found, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(sub_missing_ids[~sub_missing_ids.isin(missing_ids.none_found)])\n",
    "print(~missing_ids.none_found[missing_ids.none_found.astype(\"str\").isin(sub_missing_ids)])\n",
    "\n",
    "new_missing_ids = [*missing_ids.none_found, *sub_missing_ids[~sub_missing_ids.isin(missing_ids.none_found)]]\n",
    "#new_missing_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b060463a-913e-4f5b-a67c-dc0fafcde2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 0\n",
      "{'meta': {'name': 'openaq-api', 'license': '', 'website': '/', 'page': 1, 'limit': 1, 'found': 0}, 'results': []}\n",
      "no entries found for id 1380\n",
      "{'meta': {'name': 'openaq-api', 'license': '', 'website': '/', 'page': 1, 'limit': 1, 'found': 0}, 'results': []}\n",
      "no entries found for id 1380\n"
     ]
    }
   ],
   "source": [
    "all_measurments = pd.DataFrame()\n",
    "no_entries_id = list()\n",
    "\n",
    "\n",
    "for n,i in enumerate(new_missing_ids, start = 0):\n",
    "    if(n == 0):\n",
    "        print(\"n = 0\")\n",
    "    elif((n%150) == 0):\n",
    "        time.sleep(3)\n",
    "    try:\n",
    "        foo = get_measument_per_location_special(i)\n",
    "    except CustomException as e:\n",
    "        no_entries_id.append(i)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error at ID: \",i)\n",
    "        print(e)\n",
    "        continue\n",
    "    ## Extract the period between \n",
    "    all_measurments = pd.concat([all_measurments, foo])\n",
    "    #print(fires)\n",
    "        #fr_pd = pd.DataFrame(fires, columns=[\"lat\", \"lon\", \"farea\", \"data_source\"])\n",
    "    all_measurments.to_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/\" + str(date.today().strftime(\"%Y%m%d\"))+  \".csv\")\n",
    "    tmp_df = pd.DataFrame(no_entries_id, columns= [\"none_found\"])\n",
    "    tmp_df.to_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/\" + \"missing_ids\"+ str(date.today().strftime(\"%Y%m%d\"))+  \".csv\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bcd56f7c-ba4b-4daf-9ded-7413c00a2081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# url = \"https://api.openaq.org/v2/measurements?date_from=2023-05-01T00%3A00%3A00&date_to=2023-09-30T00%3A00%3A00&limit=7000&page=50&offset=0&sort=desc&has_geo=true&parameter_id=2&radius=1000&country=CA&order_by=datetime&entity=null\"\n",
    "\n",
    "# headers = {\"accept\": \"application/json\"}\n",
    "\n",
    "# response = requests.get(url, headers=headers)\n",
    "\n",
    "# test = response.json()\n",
    "# measurements = pd.DataFrame(test['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2b5c3d8f-937d-40ce-9235-709e7fc44043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Put data into useful forms for write-out\n",
    "\n",
    "all_sens = pd.concat([sensors, sensors2, sensor3, sensor4, sensor5, sensor6], ignore_index = True)\n",
    "all_sens = all_sens.drop_duplicates()\n",
    "\n",
    "\n",
    "## Unpack nested column information\n",
    "locs = unpack(locs, 'coordinates')\n",
    "tmp = unpack(locs, 'manufacturers')\n",
    "tmp = tmp.rename(columns={0:\"manufacturers\"})\n",
    "locs = unpack(tmp, 'manufacturers')\n",
    "\n",
    "## Write out location data\n",
    "\n",
    "locs.to_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/\" + \"Locations_formatted.csv\") \n",
    "\n",
    "\n",
    "locs = locs[[\"id\", \"city\",\"lastUpdated\", \"firstUpdated\", \"measurements\", \"latitude\", \"longitude\", \"modelName\", \"manufacturerName\"]] # Subset to columns that are more informative for merge\n",
    "\n",
    "all_sens = all_sens[['id', 'name', 'hour', 'day', 'month', 'year', 'hod',\n",
    "       'dow', 'average', 'measurement_count', 'parameter', 'parameterId',\n",
    "       'displayName', 'unit', 'first_datetime', 'last_datetime']] # Also subset to infotmative colmns\n",
    "all_sens = all_sens.drop_duplicates()\n",
    "\n",
    "### Put data into formates to prepare for merging\n",
    "all_sens = all_sens[['id', 'name', 'hour','average', 'measurement_count', 'parameter',\n",
    "       'displayName', 'unit']]\n",
    "all_sens.city = all_sens.city.astype('str')\n",
    "all_sens.id = all_sens.id.astype(\"float\").apply(math.floor)\n",
    "all_sens.id = all_sens.id.astype(\"str\")\n",
    "locs.id = locs.id.astype(\"str\")\n",
    "\n",
    "all_sens = all_sens.merge(locs, on = \"id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "794a16b4-01ed-44d2-a4ed-2fea8b9f1d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Group by ID to get summary statistics\n",
    "\n",
    "sens_mean = all_sens.groupby([\"id\",'name','parameter',\n",
    "       'displayName', 'unit', 'city', 'lastUpdated', 'firstUpdated',\n",
    "       'latitude', 'longitude', 'modelName',\n",
    "       'manufacturerName' ]).average.mean()\n",
    "sens_mean = sens_mean.reset_index()\n",
    "\n",
    "max_sens = all_sens.groupby([\"id\"]).average.max()\n",
    "max_sens = max_sens.reset_index()\n",
    "max_sens = max_sens.rename(columns={\"average\":\"max\"})\n",
    "\n",
    "sens_mean = sens_mean.merge(max_sens, on = [\"id\"])\n",
    "\n",
    "mean_sens = all_sens.groupby([\"id\"]).average.mean()\n",
    "mean_sens = mean_sens.reset_index()\n",
    "mean_sens = mean_sens.rename(columns={\"average\":\"mean\"})\n",
    "\n",
    "sens_mean = sens_mean.merge(mean_sens, on = [\"id\"])\n",
    "\n",
    "quant_upper = all_sens.groupby([\"id\"]).average.quantile(0.975)\n",
    "quant_upper = quant_upper.reset_index()\n",
    "quant_upper = quant_upper.rename(columns={\"average\":\"quant_97.5\"})\n",
    "\n",
    "sens_mean = sens_mean.merge(quant_upper, on = [\"id\"])\n",
    "\n",
    "quant_lower = all_sens.groupby([\"id\"]).average.quantile(0.025)\n",
    "quant_lower = quant_lower.reset_index()\n",
    "quant_lower = quant_lower.rename(columns={\"average\":\"quant_02.5\"})\n",
    "\n",
    "sens_mean = sens_mean.merge(quant_lower, on = [\"id\"])\n",
    "\n",
    "quant_25 = all_sens.groupby([\"id\"]).average.quantile(0.25)\n",
    "quant_25 = quant_25.reset_index()\n",
    "quant_25 = quant_25.rename(columns={\"average\":\"quant_25\"})\n",
    "\n",
    "sens_mean = sens_mean.merge(quant_25, on = [\"id\"])\n",
    "\n",
    "quant_75 = all_sens.groupby([\"id\"]).average.quantile(0.75)\n",
    "quant_75 = quant_75.reset_index()\n",
    "quant_75 = quant_75.rename(columns={\"average\":\"quant_75\"})\n",
    "\n",
    "sens_mean = sens_mean.merge(quant_75, on = [\"id\"])\n",
    "\n",
    "min_sens = all_sens.groupby([\"id\"]).average.min()\n",
    "min_sens = min_sens.reset_index()\n",
    "min_sens = min_sens.rename(columns={\"average\":\"min\"})\n",
    "\n",
    "sens_mean = sens_mean.merge(min_sens, on = [\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7175c8e5-c73b-4a60-9d80-086c04d27c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sens_mean = sens_mean.drop(\"average\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "569a7e2a-de9e-4715-b853-cb12cb7593d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sens_mean.to_csv(\"/projects/old_shared/Smoke_over_Canada_2023/openAQ_measurements/\" + \"Summary_statistics_pm2.5_sensors_in_CA.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fireatlas_oct4_2)",
   "language": "python",
   "name": "fireatlas_oct4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
